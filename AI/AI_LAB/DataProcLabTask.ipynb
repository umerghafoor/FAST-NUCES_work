{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,OrdinalEncoder,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/sumony2j/Data_Cleaning_Preprocessing/refs/heads/main/AB_NYC_2019.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: View the Data\n",
    "Once the data is loaded, take a look at the first few rows to get an idea of what it contains.\n",
    "\n",
    "**Task**: Use a function to display the first five rows of the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Check Dataset Dimensions\n",
    "Knowing the size of the dataset can help you plan data processing steps.\n",
    "\n",
    "**Task**: Use a function to display the dimensions (rows and columns) of `df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Get Data Overview\n",
    "Understanding the data types and number of non-null entries in each column is crucial for data cleaning.\n",
    "\n",
    "**Task**: Use a function to get a summary of `df` and its columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Check for Missing or NULL Values\n",
    "Some columns may have missing data. Identifying these will guide you in handling missing values.\n",
    "\n",
    "**Task**: Write code to find the total number of missing values in each column of `df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Drop Unnecessary Columns\n",
    "Some columns in the dataset may not be relevant for analysis. In this exercise:\n",
    "\n",
    "**Task**: Write code to drop these columns from `df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Handle Missing Values\n",
    "The `reviews_per_month` column has missing values. Let's replace missing values with the most frequent value in this column.\n",
    "\n",
    "**Task**:\n",
    "- Initialize a `SimpleImputer` with the strategy `\"most_frequent\"`.\n",
    "- Use it to fill missing values in the `reviews_per_month` column of `df`.\n",
    "- After coding this task. Add another code cell to explore other imputer strategies. Then add another MD cell to discuss the pros and cons of each. Test at least 2 more strats \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Identify Categorical Columns\n",
    "Categorical columns hold non-numeric data and will require encoding. Identify these columns in `df`.\n",
    "\n",
    "**Task**:\n",
    "- Write code to find columns with an `object` data type.\n",
    "- Print each column name and the number of unique values it contains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Check Unique Room Types\n",
    "The `room_type` column has different categories. Listing them will help you understand the types of rentals available.\n",
    "\n",
    "**Task**: Write code to find the unique values in the `room_type` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Prepare Room Type Data for Encoding\n",
    "Convert the `room_type` column to a NumPy array and reshape it for encoding.\n",
    "\n",
    "**Task**:\n",
    "- Convert `room_type` to a list and then to a NumPy array.\n",
    "- Reshape it to have one column and many rows (use `-1` as the first dimension).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Encode Room Type\n",
    "Use `OrdinalEncoder` to transform the `room_type` array.\n",
    "\n",
    "**Task**:\n",
    "- Initialize an `OrdinalEncoder`.\n",
    "- Apply it to `room_type` and update `df['room_type']` with the encoded values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: One-Hot Encode Neighborhood\n",
    "Convert `neighbourhood` into binary columns using `OneHotEncoder`.\n",
    "\n",
    "**Task**:\n",
    "- Extract the `neighbourhood` column as a DataFrame.\n",
    "- Use `OneHotEncoder` to encode it, setting `sparse_output=False`.\n",
    "- Store the result as a new DataFrame with columns named after each neighborhood.\n",
    "- Also add a markdown after the code cell and explain why we are using One-Hot encoding and what alternatives we can use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Add Encoded Columns to DataFrame\n",
    "Add the encoded neighborhood columns back to `df`.\n",
    "\n",
    "**Task**: Write code to concatenate the one-hot encoded neighborhood DataFrame with `df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15: Encode Neighborhood Group\n",
    "One-hot encode the `neighbourhood_group` column.\n",
    "\n",
    "**Task**:\n",
    "- Extract the `neighbourhood_group` column.\n",
    "- Apply one-hot encoding to this column as you did with `neighbourhood`.\n",
    "- Print the categories to confirm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16: Final Data Check\n",
    "After processing the data, check the first few rows of `df` to confirm the transformations.\n",
    "\n",
    "**Task**: Write code to display the first few rows of `df`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
